---
{"dg-publish":true,"permalink":"/Epidemiology_and_Health_Statistics/math/pttjx/非参数检验作业/","dgPassFrontmatter":true}
---



### 10.3

1. 提出零假设和备择假设，记m为该小镇成年男性每年饮酒量的中位数：
$$H_0:m \geq 15;\qquad H_{\alpha}:m \lt 15$$
记P为该小镇中一位成年男性一年饮酒量≥15L的概率，上述的零假设和备择假设等价于：
$$H_0:P \geq 0.5;\qquad H_{\alpha}:P \lt 0.5$$
记随机变量X为一个样本中成年男性饮酒量大于15L，即符号为“+”的个数，那么如果零假设成立，X应该服从P=0.5的二项分布
2. 计算p值
从题目给的数据可计算出“+”的个数为1，“-”的个数为9，X~B（10, 0.5）
$$p=P(X\leq1)=P(X=0)+P(X=1)=0.5^{10}+C_{10}^10.5^{10}=0.01$$
3. 做出判断
由于计算的p值很小，所以我们拒绝零假设。该记者说的话不正确。

### 10.4

（1）计算A、B两家书店同一本图书的价格之差，如果书店A的价格高于书店B，记为“+”，如果书店A的价格低于书店低于书店B，记为“-”，相同则没有对应的符号。以p代表“+”出现的概率。据此，我们可以提出零假设和备择假设
$$H_0:p\leq0.5;\qquad H_{\alpha}:p\gt0.5$$
（2）记X为样本中出现“+”的次数，由于《大学英语》在两家书店的价格相同，我们将它剔除，则有$X\sim B(9,0.5)$
（3）样本中“+”的次数为：1，计算p值：
$$p=P(X\geq1)=1-P(X=0)=1-0.5^9=0.998$$
p值很大，我们接受零假设，认为书店A图书的价格低于书店B

### 10.7

记$d_i$为每位顾客二层服务满意度与一层服务满意度打分的差值，列表如下：

|顾客编号i|$d_i$|$d_i$绝对值|秩$T_i$|+秩|-秩|
|---|---|---|---|---|---|
|1|-1|1|1.5||1.5|
|2|1|1|1.5|1.5||
|3|-5|5|8.5||8.5|
|4|-6|6|10||10|
|5|0|0|-|-|-|
|6|-3|3|4.5||4.5|
|7|5|5|8.5|8.5||
|8|-4|4|6.5||6.5|
|9|-2|2|3||3|
|10|-7|7|11||11|
|11|-4|4|6.5||6.5|
|12|3|3|4.5|4.5||
||||秩和|14.5|51.5|

计算检验统计量T
$$T=min\{T^+,T^-\}=14.5$$
查表得
$$T=14.5>T_{0.05}(11)=10$$
故我们拒绝该零假设，认为顾客对商场一层和二层的服务满意程度不相等。

用R做威尔科克森符号秩和检验：
```r
fr_sorce <- c(8, 9, 10, 9, 5, 8, 3, 9, 7, 8, 10, 5)
sd_sorce <- c(7, 10, 5, 3, 5, 5, 8, 5, 5, 1, 6, 8)
wil_test_1 <- data.frame(fr_sorce, sd_sorce)
wilcox.test(fr_sorce, sd_sorce, data = wil_test_1, alternative = "two.side", paired = TRUE)
```
输出结果：
```{r}
Warning: 无法精確計算带连结的p值Warning: 有0时无法計算精確的p值
	Wilcoxon signed rank test with continuity correction

data:  fr_sorce and sd_sorce
V = 51.5, p-value = 0.1088
alternative hypothesis: true location shift is not equal to 0
```
结果支持拒绝零假设，认为顾客对商场一层和二层的服务满意程度不相等

### 10.13

提出假设：
$$H_0:这四个专业的学生英语程度相同$$
$$H_\alpha:至少有两个专业的学生英语程度不同$$
将英语成绩从低到高排名得到每位同学的混合秩，再计算不同专业学生的秩和：
$T_{tj}=96.5,n_{tj}=6;\quad T_{kj}=82.5,n_{kj}=7;\quad T_{jsj}=122,n_{jsj}=6;\quad T_{gjmy}=50,n_{gjmy}=7$
总体样本数为26，计算H统计量：
$$\begin{align}
H&=[\frac{12}{n(n+1)}\sum_{i=1}^k\frac{T_i^2}{n_i}]-3(n+1)
\\&=\frac{12}{26\times27}(\frac{96.5^2}6+\frac{82.5^2}7+\frac{122^2}6+\frac{50^2}7)-3\times27
\\&=10.66
\end{align}$$
由于四个专业中抽取的学生数均大于5，H统计量服从自由度为3的卡方分布，当显著性水平取0.05时，$H=10.66>\chi_{0.05}^2(3)=7.81$
故我们拒绝零假设，认为“不同专业的学生英语程度也不同”成立。

用R做克鲁斯卡尔-沃利斯检验：
```r
library(readr)
eg_test <- read_csv("eg_test.csv") # 先导入数据，该数据包括两列，第一列eg_test$eg_score 为每个同学的英语分数，第二列eg_test$major 为该同学的专业
eg_test
kruskal.test(eg_sorce ~ major, data = eg_test)
```
输出结果：
```{r}
Rows: 26 Columns: 3── Column specification ──────────────────────────────────────────────────────────────────────
Delimiter: ","
chr (1): major
dbl (2): eg_sorce, rank
ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
	Kruskal-Wallis rank sum test

data:  eg_sorce by major
Kruskal-Wallis chi-squared = 10.672, df = 3, p-value = 0.01364
```
同样认为“不同专业的学生英语程度也不同”成立。

### 10.14

用非参数检验更适合应用于该数据，因为该数据类型为序数数据，且其总体分布未知，用非参数检验更合适，由于涉及两组以上的比较，故选择克鲁斯卡尔-沃利斯检验：
零假设：三种绿茶的受欢迎程度一样
备择假设：至少有两种绿茶的受欢迎程度不一样
先编秩，将每个人的评分从低到高排序，得到三种绿茶的秩和：
$T_A=82.5,n_A=7;\quad T_B=89.5,n_B=6;\quad T_C=81,n_C=9$
总样本量为22，计算H统计量：
$$\begin{align}
H&=[\frac{12}{n(n+1)}\sum_{i=1}^k\frac{T_i^2}{n_i}]-3(n+1)
\\&=\frac{12}{22\times23}(\frac{82.5^2}7+\frac{89.5^2}6+\frac{81^2}9)-3\times23
\\&=3
\end{align}$$
由于三种绿茶中抽取的评价人数均大于5，H统计量服从自由度为2的卡方分布，当显著性水平取0.05时$H=3<\chi_{0.05}^2(2)=5.99$
故我们接受零假设，认为三种绿茶的受欢迎程度一样

R代码
```r
library(readr)
tea_test <- read.csv("tea_test.csv")
tea_test
kruskal.test(score ~ kinds, data = tea_test)
```
```
Kruskal-Wallis rank sum test

data:  score by kinds
Kruskal-Wallis chi-squared = 3.1622, df = 2, p-value = 0.2058
```
输出结果支持接受零假设，认为三种绿茶的受欢迎程度一样

---
# 时间序列分析作业

### 11.2

用R绘制时间序列图：
```r
year <- c(1992:2005)
crimal_num <- c(757.7, 747.1, 713.6, 684.5, 636.6, 611, 567.6, 523, 506.5, 504.5, 494.4, 475.8, 463.2, 469.2)
plot(year, crimal_num, type="o",
	xlab = "年份", ylab = "犯罪人数/10万人",
	main = "美国1992~2005年全干过每10万居民中的犯罪人数时间序列图")
```
![Epidemiology_and_Health_Statistics/math/pttjx/images/Pasted image 20231217183909.png|400](/img/user/Epidemiology_and_Health_Statistics/math/pttjx/images/Pasted%20image%2020231217183909.png)
从时间序列图中可以看到，美国每年的罪犯人数随着年份的增加呈明显的下降趋势，该序列不是平稳序列

### 11.4

(1)用R绘制时间序列图，代码如下（季度用1~27代表）：
```r
quarter_hk <- c(1:27)
pollute_hrs <- c(1057, 275, 481, 1537, 1160, 393, 392, 954, 586, 635, 387, 1542, 1504, 438, 355, 1333, 846, 436,
                 208, 1263, 727, 267, 185, 1451, 1353, 463, 290)
plot(quarter_hk, pollute_hrs, type = "o",
     xlab = "季度", ylab = "空气污染偏高以上小时数",
     main = "香港2005-2011年各个季度沙田地区空气污染指数\n达到偏高以上的小时数时间序列图")
```
![Epidemiology_and_Health_Statistics/math/pttjx/images/Pasted image 20231217183039.png|400](/img/user/Epidemiology_and_Health_Statistics/math/pttjx/images/Pasted%20image%2020231217183039.png)
从时间序列图来看，香港沙田地区空气污染指数达到偏高以上的小时数受季度影响较为明显，第一和第四季度的空气污染指数偏高以上的小时数最多，第二第三季度相对较少。从长期来看，空气污染指数偏高以上的小时数有着较小的下降趋势。
(2)
3期平均预测值及其平均绝对误差(MAE)、均方误差(MSE)、平均绝对百分比误差(MAPE)
```r
# 计算3期移动平均
hours_yc <- c() 
for (i in 4:27){
  hours_yc_i = (pollute_hrs[i-3] + pollute_hrs[i-2] + pollute_hrs[i-1])/3
  hours_yc[i] <- hours_yc_i 
}
hours_yc
# 计算平均绝对误差(MAE)、均方误差(MSE)、平均绝对百分比误差(MAPE)
sum_abs_err = 0; sum_abs_err_2 = 0; per_err = 0
for (i in 4:27) {
  abs_err_i = abs(hours_yc[i] - pollute_hrs[i])
  sum_abs_err = sum_abs_err + abs_err_i
  sum_abs_err_2 = sum_abs_err_2 + abs_err_i^2
  per_err = per_err + abs_err_i / pollute_hrs[i]
}
MAE_hk <- sum_abs_err / 24
MSE_hk <- sum_abs_err_2 / 24
MAPE_hk <- per_err / 24
MAE_hk; MSE_hk; MAPE_hk
```
~~~
 [1]        NA        NA        NA  604.3333  764.3333 1059.3333 1030.0000  648.3333  579.6667  644.0000  725.0000
[12]  536.0000  854.6667 1144.3333 1161.3333  765.6667  708.6667  844.6667  871.6667  496.6667  635.6667  732.6667
[23]  752.3333  393.0000  634.3333  996.3333 1089.0000
[1] 551.5139
[1] 387883.8
[1] 1.078514
~~~
5期移动平均预测值及其平均绝对误差(MAE)、均方误差(MSE)、平均绝对百分比误差(MAPE)
```r
# 计算5期移动平均
hours_yc_5 <- c() 
for (i in 6:27){
  hours_yc_i = (pollute_hrs[i-5] + pollute_hrs[i-4] + pollute_hrs[i-3] + pollute_hrs[i-2] + pollute_hrs[i-1])/5
  hours_yc_5[i] <- hours_yc_i 
}
hours_yc_5
# 计算平均绝对误差(MAE)、均方误差(MSE)、平均绝对百分比误差(MAPE)
sum_abs_err = 0; sum_abs_err_2 = 0; per_err = 0
for (i in 6:27) {
  abs_err_i = abs(hours_yc_5[i] - pollute_hrs[i])
  sum_abs_err = sum_abs_err + abs_err_i
  sum_abs_err_2 = sum_abs_err_2 + abs_err_i^2
  per_err = per_err + abs_err_i / pollute_hrs[i]
}
MAE_hk <- sum_abs_err / 22
MSE_hk <- sum_abs_err_2 / 22
MAPE_hk <- per_err / 22
MAE_hk; MSE_hk; MAPE_hk
```
~~~
 [1]     NA     NA     NA     NA     NA  902.0  769.2  792.6  887.2  697.0  592.0  590.8  820.8  930.8  901.2  845.2
[17] 1034.4  895.2  681.6  635.6  817.2  696.0  580.2  530.0  778.6  796.6  743.8
[1] 441.9455
[1] 246487.6
[1] 0.8604515
~~~
可以看到，5期移动平均预测值的平均绝对误差(MAE)、均方误差(MSE)、平均绝对百分比误差(MAPE)均较3期移动平均值要小，说明其预测更准确。

(3)
```r
# 计算加权3期移动平均
hours_yc_3 <- c() 
for (i in 4:27){
  hours_yc_i = (pollute_hrs[i-3]/6 + pollute_hrs[i-2]/3 + pollute_hrs[i-1]/2)
  hours_yc_3[i] = hours_yc_i
}
hours_yc_3
```
得到：
~~~
[1]        NA        NA        NA  508.3333  974.6667 1172.5000  839.3333  520.3333  673.1667  676.3333  671.8333
[12]  502.8333 1005.8333 1330.5000  977.3333  574.1667  857.8333  926.5000  722.1667  390.3333  773.5000  819.1667
[23]  586.3333  302.6667  831.6667 1191.0000  924.3333
~~~

### 11.7

（1）绘制时间序列图

```r
# 导入数据
library(readr)
sales <- read.csv("sales.csv")
sales
# 绘制时间序列图
plot(sales$date, sales$sales, type = "o",
     xlab = "日期", ylab = "销售额/万元",
     main = "某大型百货公司近4年各季度销售额时间序列图")
```
![Epidemiology_and_Health_Statistics/math/pttjx/images/Pasted image 20231217205718.png|500](/img/user/Epidemiology_and_Health_Statistics/math/pttjx/images/Pasted%20image%2020231217205718.png)
从时间序列图可看出，销售额受季度因素的影响较大，第三、第四季度的销售额显著高于第 一、二季度的销售额，且第三季度的销售额最高。从长期来看，该超市的营业额呈明显的上 升趋势。

(2) 
```r
# 求移动平均
average_4 <- c()
for (i in 4:16) {
  average_4_i = (sales$sales[i-3] + sales$sales[i-2] + sales$sales[i-1] + sales$sales[i])/4
  average_4[i] = average_4_i 
}
average_4
# 求中心化移动平均(cma)
cma <- c()
# 一般情况是收尾各去掉(n/2)，这样做是为了计算季节指数方便
for (i in 3:14) {
  cma_i = (average_4[i+1]+average_4[i+2])/2
  cma[i] = cma_i
}
cma
# 求季节平均
y_cma <- c()
for (i in 3:14) {
  y_cma_i = sales$sales[i]/cma[i]
  y_cma[i] = y_cma_i
}
y_cma
S_1 = (y_cma[5] + y_cma[9] + y_cma[13])/3
S_2 = (y_cma[6] + y_cma[10] + y_cma[14])/3
S_3 = (y_cma[3] + y_cma[7] + y_cma[11])/3
S_4 = mean(y_cma[4] + y_cma[8] + y_cma[12])/3
# 这一部分应该有更好的代码实现方法，暂时没想到，具体来说就是第一个是一个周期中第(n/2+1)个数
# 最后一个数是一个周期中的第(n/2-1)个数，一共能算出N/n-1个周期，需要计算周期中对应数的平均值
S_1; S_2; S_3; S_4
```
经过计算分别得到第一季度的季节指数$S_1=0.71$，第二季度为$S_2=0.89$，第三季度为$S_3=1.4$ 第四季度为$S_4=1.00$

(3) 

```r
library(readr)
sales <- read.csv("sales.csv")
# 看是否有线性关系
plot(sales$date, sales$sales_s, type = "o")
# 建立回归模型
fit <- lm(sales_s~date, data = sales)
summary(fit)
```
![Epidemiology_and_Health_Statistics/math/pttjx/images/Pasted image 20231217205853.png|500](/img/user/Epidemiology_and_Health_Statistics/math/pttjx/images/Pasted%20image%2020231217205853.png)
可以看到，剔除季节因子后，销售额和时间明显呈线性关系，得到剔除季节因子后的回归模型为： $$\widehat{Y}_{-S}=6320.1+1703.3t$$ 用该模型得到趋势预测值， 再用趋势预测值*季度指数得到最终预测值。

```r
y_yc <- 1703.3*sales$date + 6320.1
for (i in 1:16) {
  if(i%%4 == 1){
    y_yc[i] = y_yc[i]*0.71
  }else if(i%%4 == 2){
    y_yc[i] = y_yc[i]*0.89
  }else if(i%%4 == 3){
    y_yc[i] = y_yc[i]*1.4
  }else if(i%%4 == 0){
    y_yc[i] = y_yc[i]*1
  }
}
y_yc
``` 
最终的预测值为：
```{r}
 [1]  5696.614  8656.763 16002.000 13133.300 10533.986 14720.511 25540.480 19946.500
 [9] 15371.358 20784.259 35078.960 26759.700 20208.730 26848.007 44617.440 33572.900
```